project_name: quadbot_chaser_ppo_reward_sweep_2
username: frizzerdk

env:
  name: QuadChaseEnv
  max_steps: 1000
  frame_skip: 5
  render_mode: ""
  xml_file: "quadbot.xml"

  observation_max_wheel_steer_vel: 5
  observation_max_wheel_drive_vel: 100
  observation_max_body_linear_vel: 20
  observation_max_body_angular_vel: 3
  observation_max_body_position: 10
  steer_joint_damping: 0.1
  drive_joint_damping: 0.05
  steer_actuator_gain: 2
  drive_actuator_gain: 3
  reset_noise_scale: 3
  reset_pos_offset: 2
  target_pos_distance: 3

  reward_scale_action_penalty: 1
  reward_scale_drive_action_penalty: 0.001
  reward_scale_steer_action_penalty: 1
  reward_scale_wheel_misalignment: 0.5
  reward_scale_position_penalty: 0.0
  reward_scale_success_reward: 50
  reward_scale_position_error_change: 0.0
  reward_scale_distance_closed_to_target: 0.0
  reward_scale_position_error_velocity: 50.0

  wheel_alignment_threshold: 10
  reward_scale_total: 10.0
  steer_kp: 10
  log_state: true
  log_sensor: true
  log_reward: true
  log_observation: true
  plot_summary: true
  
model:
  policy: MlpPolicy
  learning_rate: 3e-4
  n_steps: 2048
  batch_size: 256
  n_epochs: 3
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.0001
  vf_coef: 0.5
  max_grad_norm: 0.5
  use_sde: false
  sde_sample_freq: 10
  hidden_layers_size: 256
  log_std_init: -0.5

train:
  total_timesteps: 1000000
  log_interval: 1
  eval_freq: 10000
  n_eval_episodes: 5
  deterministic_eval: false
  render_eval: true
  video_freq: 20
  video_length: 1000

save:
  model_dir: ./models
  save_freq: 50000

monitor_dir: ./monitor/
video_dir: ./video
video_frame_skip: 5
log_dir: ./logs
checkpoint_path: ./checkpoints
is_sweep: false
tensorboard_log: ./tensorboard